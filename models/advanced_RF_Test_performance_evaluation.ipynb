{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa456a2",
   "metadata": {},
   "source": [
    "> Advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9016e",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62438f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062874e",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate x and y data\n",
    "\n",
    "feature_columns = data.columns[:-1]\n",
    "\n",
    "x_data = data[feature_columns]\n",
    "y_data = data['PCOS_Diagnosis'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a91b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde4de5",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "\n",
    "Note: Feature scaling and one-hot encoding are generally not required for tree-based algorithms.\n",
    "\n",
    "- For categorical columns, label encoding (assigning integers to categories) is typically sufficient for tree-based models like Decision Trees and Random Forests. One-hot encoding can lead to unnecessary splits and higher dimensionality, which may reduce model efficiency.\n",
    "- Feature scaling (e.g., normalization or standardization) is not needed because tree-based models are not sensitive to feature magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20290cad",
   "metadata": {},
   "source": [
    "### Datasets Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_shuf_split = StratifiedShuffleSplit(n_splits = 1, \n",
    "                                            test_size = 0.3, \n",
    "                                            random_state = 42)\n",
    "\n",
    "train_idx, test_idx = next(strat_shuf_split.split(x_data, y_data))\n",
    "\n",
    "# Create train and test dataframes\n",
    "\n",
    "X_train = x_data.loc[train_idx]\n",
    "y_train = y_data[train_idx]\n",
    "\n",
    "X_test = x_data.loc[test_idx]\n",
    "y_test = y_data[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92d174",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings about too few trees form the early models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb15ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the random forest estimator\n",
    "# Note that the number of trees is not setup here\n",
    "# In scikit-learn, warm_start is a parameter used in ensemble models like RandomForestClassifier to reuse the results from a previous .fit() call. Instead of starting from scratch, it allows the model to incrementally add more estimators (like decision trees) to the existing ensemble.\n",
    "\n",
    "\n",
    "RF = RandomForestClassifier(oob_score = True,\n",
    "                            random_state = 42,\n",
    "                            warm_start = True,\n",
    "                            n_jobs = -1)\n",
    "\n",
    "\n",
    "oob_list = list()  # oob - out-of-bag score\n",
    "\n",
    "# Iterate through all of the possibilities for number of trees\n",
    "\n",
    "for n_trees in [15, 20, 30, 40, 50, 100, 150, 200, 300, 400]:\n",
    "\n",
    "    # Use this to set number of trees\n",
    "    RF.set_params(n_estimators = n_trees)\n",
    "\n",
    "    RF.fit(X_train, y_train)\n",
    "\n",
    "    oob_error = 1 - RF.oob_score_\n",
    "\n",
    "    oob_list.append(pd.Series({'n_trees': n_trees, 'oob': oob_error}))\n",
    "\n",
    "rf_oob_df = pd.concat(oob_list, axis =1).T.set_index('n_trees')\n",
    "rf_oob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "ax = rf_oob_df.plot(legend = False, marker = 'o', figsize = (14,7), linewidth =5)\n",
    "ax.set(ylabel = 'out-of-bag error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddd40d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd32f333",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning & Cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
